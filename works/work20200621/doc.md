


In the following case studies,
the effect of PD-controller is investigated 
by comparing the behaviours between the system controlled by P-controller
and the ones contorlled by PD-controller.

It's supposed that 
the response against stepwise disturbance 
is improved by the derivative factor,
which means that abrubt change of error amplifies the action
via the derivative factor and the stepwise error can be diminished more quickly  than in the case of controlling by P-controller.

The specification of agent is here.
Action consists of the following twofold,
the proportional term obtained by multiplying a value of error by a proportional gain
and the derivative term obtained by multiplying a derivative gain and a value of slope over the specific length time series of error, 
where the length of the series of errors is specified by a parameter: $nSeq$.

The following case studies is hilighted as follow:
>>
The case study #1 compares the behaviours of P- and PD-controller
with a set of hyper parameter.
>>
The case study #2 shows the diffrence depending on the hyperparameter: gamma,
which should controll the weight on the reward over the time horizon:
the closer gamma is to 1 and the longer the time horizon is and the agent responses against the error less quickly.
>>
The case study #3 looks through the effect of the regularation parameter
since it's concerned the expese from the quckness of agent,
which means that the disturbance generated by the agent might be amplified by the large derivative gain.
>>
The case study #4 takes the attetions over the relation between the parameter gamma and the length of error series.

